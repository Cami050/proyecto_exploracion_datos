{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cami050/proyecto_exploracion_datos/blob/main/Proyecto_de_Datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1a97cf9"
      },
      "source": [
        "### 1.3.1 Cargar el dataset después de subirlo manualmente\n",
        "\n",
        "Si subiste tu archivo `delitos_informaticos.csv` directamente al entorno de Colab, ejecuta la siguiente celda para cargarlo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cd40ffa",
        "outputId": "72a21c47-0cd3-4c4f-8e2e-c7cc540e5b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/DELITOS_INFORMÁTICOS_20251209.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3216820501.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mruta_manual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/DELITOS_INFORMÁTICOS_20251209.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruta_manual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"¡ÉXITO! Dataset cargado desde: {ruta_manual}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/DELITOS_INFORMÁTICOS_20251209.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "ruta_manual = '/content/DELITOS_INFORMÁTICOS_20251209.csv'\n",
        "df = pd.read_csv(ruta_manual, encoding='utf-8')\n",
        "\n",
        "print(f\"¡ÉXITO! Dataset cargado desde: {ruta_manual}\")\n",
        "\n",
        "# Verificar el dataset cargado\n",
        "if 'df' in locals() and df is not None:\n",
        "    print(\"=\"*60)\n",
        "    print(\" DATASET CARGADO EXITOSAMENTE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Información básica\n",
        "    print(f\"\\n DIMENSIONES: {df.shape[0]:,} filas × {df.shape[1]} columnas\")\n",
        "\n",
        "    # Mostrar nombres de columnas\n",
        "    print(\"\\n NOMBRES DE COLUMNAS ORIGINALES:\")\n",
        "    for i, col in enumerate(df.columns, 1):\n",
        "        print(f\"   {i:2d}. {col}\")\n",
        "\n",
        "    # Mostrar primeras filas\n",
        "    print(\"\\n MUESTRA DEL DATASET (primeras 3 filas):\")\n",
        "    display(df.head(3))\n",
        "\n",
        "    # Mostrar información de tipos\n",
        "    print(\"\\n TIPOS DE DATOS:\")\n",
        "    print(df.dtypes)\n",
        "else:\n",
        "    print(\"NO SE PUDO CARGAR EL DATASET\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LU1_SWffoPA1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763c3d67-8cba-4090-f626-98abcb49c5ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            " INICIANDO PROYECTO DE ANÁLISIS DE DELITOS INFORMÁTICOS\n",
            "============================================================\n",
            "\n",
            "El DataFrame 'df' no ha sido cargado aún o está vacío. Procediendo con la carga...\n",
            "\n",
            " Intentando cargar desde /gdrive...\n",
            " Error con /gdrive: [Errno 2] No such file or directory: '/gdrive/MyDrive/Datasets/DELITOS_INFORMÁTICOS_20251209.csv'\n",
            "\n",
            " Intentando cargar desde /content/drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " Error con /content/drive: [Errno 2] No such file or directory: '/content/drive/MyDrive/Datasets/DELITOS_INFORMÁTICOS_20251209.csv'\n",
            "\n",
            " Buscando archivos subidos manualmente...\n",
            " No se encontraron archivos CSV en /content\n",
            "\n",
            " Por favor, sube tu archivo manualmente:\n",
            "   1. Haz clic en el ícono de carpeta  en el panel izquierdo\n",
            "   2. Haz clic en 'Subir'\n",
            "   3. Selecciona tu archivo CSV\n",
            "   4. Luego ejecuta: df = pd.read_csv('/content/DELITOS_INFORMÁTICOS_20251209.csv')\n",
            " NO SE PUDO CARGAR EL DATASET\n",
            "\n",
            " SOLUCIONES:\n",
            "   1. Verifica que el archivo existe en Google Drive\n",
            "   2. Verifica que tiene permisos de lectura\n",
            "   3. Intenta subirlo manualmente a Colab\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# ##  CONFIGURACIÓN DEFINITIVA - CARGAR DATASET\n",
        "\n",
        "# %%\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\" INICIANDO PROYECTO DE ANÁLISIS DE DELITOS INFORMÁTICOS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Verificar si el DataFrame 'df' ya está cargado por una celda anterior (ej. 9cd40ffa)\n",
        "if 'df' in locals() and df is not None and not df.empty:\n",
        "    print(\"\\nEl DataFrame 'df' ya fue cargado exitosamente por una celda anterior.\")\n",
        "    print(\"Dimensiones actuales del DataFrame: {} filas x {} columnas\".format(df.shape[0], df.shape[1]))\n",
        "else:\n",
        "    print(\"\\nEl DataFrame 'df' no ha sido cargado aún o está vacío. Procediendo con la carga...\")\n",
        "    # Opción 1: Si ya montaste Drive en /gdrive\n",
        "    try:\n",
        "        print(\"\\n Intentando cargar desde /gdrive...\")\n",
        "        ruta_gdrive = \"/gdrive/MyDrive/Datasets/DELITOS_INFORMÁTICOS_20251209.csv\"\n",
        "        df = pd.read_csv(ruta_gdrive, encoding='utf-8')\n",
        "        print(f\" ¡ÉXITO! Dataset cargado desde /gdrive\")\n",
        "\n",
        "    except Exception as e1:\n",
        "        print(f\" Error con /gdrive: {e1}\")\n",
        "\n",
        "        # Opción 2: Intentar con /content/drive\n",
        "        try:\n",
        "            print(\"\\n Intentando cargar desde /content/drive...\")\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "            ruta_content = \"/content/drive/MyDrive/Datasets/DELITOS_INFORMÁTICOS_20251209.csv\"\n",
        "            df = pd.read_csv(ruta_content, encoding='utf-8')\n",
        "            print(f\" ¡ÉXITO! Dataset cargado desde /content/drive\")\n",
        "\n",
        "        except Exception as e2:\n",
        "            print(f\" Error con /content/drive: {e2}\")\n",
        "\n",
        "            # Opción 3: Usar ruta de subida manual\n",
        "            print(\"\\n Buscando archivos subidos manualmente...\")\n",
        "            import os\n",
        "\n",
        "            # Listar archivos en /content\n",
        "            archivos = os.listdir('/content')\n",
        "            archivos_csv = [f for f in archivos if f.lower().endswith('.csv')]\n",
        "\n",
        "            if archivos_csv:\n",
        "                print(f\" Archivos CSV encontrados en /content: {archivos_csv}\")\n",
        "                for archivo in archivos_csv:\n",
        "                    if 'delito' in archivo.lower():\n",
        "                        ruta_manual = f\"/content/{archivo}\"\n",
        "                        df = pd.read_csv(ruta_manual, encoding='utf-8')\n",
        "                        print(f\" Dataset cargado desde: {ruta_manual}\")\n",
        "                        break\n",
        "            else:\n",
        "                print(\" No se encontraron archivos CSV en /content\")\n",
        "                print(\"\\n Por favor, sube tu archivo manualmente:\")\n",
        "                print(\"   1. Haz clic en el ícono de carpeta  en el panel izquierdo\")\n",
        "                print(\"   2. Haz clic en 'Subir'\")\n",
        "                print(\"   3. Selecciona tu archivo CSV\")\n",
        "                print(\"   4. Luego ejecuta: df = pd.read_csv('/content/DELITOS_INFORMÁTICOS_20251209.csv')\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ##  VERIFICACIÓN DEL DATASET CARGADO\n",
        "\n",
        "# %%\n",
        "if 'df' in locals() and df is not None:\n",
        "    print(\"=\"*60)\n",
        "    print(\" DATASET CARGADO EXITOSAMENTE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Información básica\n",
        "    print(f\"\\n DIMENSIONES: {df.shape[0]:,} filas × {df.shape[1]} columnas\")\n",
        "\n",
        "    # Mostrar nombres de columnas\n",
        "    print(\"\\n NOMBRES DE COLUMNAS ORIGINALES:\")\n",
        "    for i, col in enumerate(df.columns, 1):\n",
        "        print(f\"   {i:2d}. {col}\")\n",
        "\n",
        "    # Mostrar primeras filas\n",
        "    print(\"\\n MUESTRA DEL DATASET (primeras 3 filas):\")\n",
        "    display(df.head(3))\n",
        "\n",
        "    # Mostrar información de tipos\n",
        "    print(\"\\n TIPOS DE DATOS:\")\n",
        "    print(df.dtypes)\n",
        "\n",
        "else:\n",
        "    print(\" NO SE PUDO CARGAR EL DATASET\")\n",
        "    print(\"\\n SOLUCIONES:\")\n",
        "    print(\"   1. Verifica que el archivo existe en Google Drive\")\n",
        "    print(\"   2. Verifica que tiene permisos de lectura\")\n",
        "    print(\"   3. Intenta subirlo manualmente a Colab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "436d5223"
      },
      "source": [
        "### Eliminación de columnas no necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c8c1d9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80f75db3-f53d-43d8-f4b9-a568e7c5cd29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El DataFrame 'df' no está definido o está vacío. Por favor, asegúrate de haber cargado el dataset primero.\n"
          ]
        }
      ],
      "source": [
        "if 'df' in locals() and df is not None:\n",
        "    print(\"Columnas antes de eliminar:\", df.columns.tolist())\n",
        "    print(\"Dimensiones antes de eliminar:\", df.shape)\n",
        "\n",
        "    # Eliminar las columnas 'COD_DEPTO' y 'COD_MUNI' de forma segura\n",
        "    # Usamos errors='ignore' para evitar KeyError si las columnas ya no existen.\n",
        "    df = df.drop(columns=['COD_DEPTO', 'COD_MUNI'], errors='ignore')\n",
        "\n",
        "    print(\"\\nColumnas después de eliminar:\", df.columns.tolist())\n",
        "    print(\"Dimensiones después de eliminar:\", df.shape)\n",
        "\n",
        "    print(\"\\nDataFrame después de eliminar columnas (primeras 5 filas):\")\n",
        "    display(df.head())\n",
        "else:\n",
        "    print(\"El DataFrame 'df' no está definido o está vacío. Por favor, asegúrate de haber cargado el dataset primero.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6d5da46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732ff772-d97c-4792-c0cb-461473750448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ANÁLISIS: Distribución de Delitos por Departamento (Top 5)\n",
            "======================================================================\n",
            "El DataFrame 'df' no está definido o está vacío. Por favor, carga el dataset primero.\n",
            "\n",
            "======================================================================\n",
            "FIN DEL ANÁLISIS\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ANÁLISIS: Distribución de Delitos por Departamento (Top 5)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if 'df' in locals() and df is not None:\n",
        "    # Agrupar por departamento y sumar la cantidad de delitos\n",
        "    delitos_por_departamento = df.groupby('DEPARTAMENTO')['CANTIDAD'].sum()\n",
        "\n",
        "    # Ordenar de forma descendente y obtener los 5 departamentos principales\n",
        "    top_5_departamentos = delitos_por_departamento.nlargest(5)\n",
        "\n",
        "    print(\"\\nLos cinco departamentos con mayor número de registros de delitos informáticos son:\")\n",
        "    display(top_5_departamentos.reset_index())\n",
        "\n",
        "    print(\"\\nTotal de delitos en estos Top 5 departamentos:\")\n",
        "    print(f\"  {top_5_departamentos.sum():,} delitos\")\n",
        "\n",
        "else:\n",
        "    print(\"El DataFrame 'df' no está definido o está vacío. Por favor, carga el dataset primero.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FIN DEL ANÁLISIS\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfWRHYei_1HT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "10ac8731-51e8-45ba-d332-ffd41d4a7934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "FASE 2A: PREPARACIÓN DE DATOS - TRANSFORMACIÓN DE FECHAS\n",
            "Responsable: Camila Rivera\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3553646574.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# 2.1 Identificar columnas de fecha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" Buscando columnas que contengan información de fecha...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# 2. PREPARACIÓN DE LOS DATOS - PARTE 1: PROCESAMIENTO DE FECHAS CR\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FASE 2A: PREPARACIÓN DE DATOS - TRANSFORMACIÓN DE FECHAS\")\n",
        "print(\"Responsable: Camila Rivera\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if df is not None:\n",
        "    # 2.1 Identificar columnas de fecha\n",
        "    print(\" Buscando columnas que contengan información de fecha...\")\n",
        "    columnas_fecha = [col for col in df.columns if 'fecha' in col.lower()]\n",
        "\n",
        "    if columnas_fecha:\n",
        "        columna_fecha_principal = columnas_fecha[0]\n",
        "        print(f\" Columna de fecha identificada: '{columna_fecha_principal}'\")\n",
        "\n",
        "        # 2.2 Convertir a tipo datetime\n",
        "        print(f\" Convirtiendo '{columna_fecha_principal}' a formato datetime...\")\n",
        "        try:\n",
        "            df[columna_fecha_principal] = pd.to_datetime(df[columna_fecha_principal], errors='coerce')\n",
        "            print(\" Conversión completada.\")\n",
        "        except Exception as e:\n",
        "            print(f\" Error en la conversión: {e}\")\n",
        "\n",
        "        # 2.3 Crear nuevas columnas derivadas (AÑO, MES, etc.)\n",
        "        print(\"\\n➕ Creando columnas derivadas para análisis temporal...\")\n",
        "        df['AÑO'] = df[columna_fecha_principal].dt.year\n",
        "        df['MES'] = df[columna_fecha_principal].dt.month\n",
        "        df['MES_AÑO'] = df[columna_fecha_principal].dt.strftime('%Y-%m')\n",
        "\n",
        "        print(\" Columnas creadas: 'AÑO', 'MES', 'MES_AÑO'\")\n",
        "\n",
        "        # 2.4 Análisis rápido del rango temporal\n",
        "        print(\"\\n RANGO TEMPORAL CUBIERTO POR LOS DATOS:\")\n",
        "        print(f\"   • Fecha más antigua: {df[columna_fecha_principal].min()}\")\n",
        "        print(f\"   • Fecha más reciente: {df[columna_fecha_principal].max()}\")\n",
        "        print(f\"   • Total de años únicos: {df['AÑO'].nunique()}\")\n",
        "\n",
        "    else:\n",
        "        print(\"  No se encontró una columna con 'fecha' en el nombre.\")\n",
        "        print(\"   Revisa manualmente los nombres de columna e identifica cuál contiene las fechas.\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\" FIN DE LA FASE 2A - CAMILA RIVERA\")\n",
        "    print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e308ac0"
      },
      "outputs": [],
      "source": [
        "#Soa\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "if 'top_5_departamentos' in locals() and top_5_departamentos is not None:\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    sns.barplot(x=top_5_departamentos.index, y=top_5_departamentos.values, palette='viridis')\n",
        "    plt.title('Top 5 Departamentos con Mayor Número de Delitos Informáticos')\n",
        "    plt.xlabel('Departamento')\n",
        "    plt.ylabel('Cantidad de Delitos')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"El DataFrame 'top_5_departamentos' no está definido. Por favor, ejecuta la celda anterior primero.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poCiXk9Mrhkk"
      },
      "source": [
        "Jhoyner Alejandro Soa Barajas\n",
        "\n",
        "**Pregunta Problematica**\n",
        "\n",
        "¿Cómo se distribuyen los casos de delitos informáticos entre los cinco departamentos con mayor número de registros?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}